{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxgCSmqBeuIbS5vts4215L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dawamassidiqi/Machine-Learning/blob/main/Super%20Vector%20Machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "nICeWTARdMfJ"
      },
      "outputs": [],
      "source": [
        "# Download Java Virtual Machine (JVM)\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "# Unzip the file\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "dWgLnc-kPFNY"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "keVWKAmfPG9J"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library for finding Spark\n",
        "!pip install -q findspark\n",
        "# Import the libary\n",
        "import findspark\n",
        "# Initiate findspark\n",
        "findspark.init()\n",
        "# Check the location for Spark\n",
        "findspark.find()"
      ],
      "metadata": {
        "id": "QiYHwdfOPM1t",
        "outputId": "fce4cb10-ad72-42b5-8291-bbe6fb8ad122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.0.0-bin-hadoop3.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "#SparkSession is now the entry point of Spark\n",
        "#SparkSession can also be construed as gateway to spark libraries\n",
        "  \n",
        "#create instance of spark class\n",
        "spark=SparkSession.builder.appName('housing_price_model').getOrCreate()\n",
        "  \n",
        "#create spark dataframe of input csv file\n",
        "df=spark.read.csv('/content/sample_data/california_housing_test.csv',inferSchema=True,header=True)\n",
        "df.show(10)"
      ],
      "metadata": {
        "id": "TYLl_VlVPPMO",
        "outputId": "80b0b776-f1b2-4708-ac9b-578a5061df74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -122.05|   37.37|              27.0|     3885.0|         661.0|    1537.0|     606.0|       6.6085|          344700.0|\n",
            "|   -118.3|   34.26|              43.0|     1510.0|         310.0|     809.0|     277.0|        3.599|          176500.0|\n",
            "|  -117.81|   33.78|              27.0|     3589.0|         507.0|    1484.0|     495.0|       5.7934|          270500.0|\n",
            "|  -118.36|   33.82|              28.0|       67.0|          15.0|      49.0|      11.0|       6.1359|          330000.0|\n",
            "|  -119.67|   36.33|              19.0|     1241.0|         244.0|     850.0|     237.0|       2.9375|           81700.0|\n",
            "|  -119.56|   36.51|              37.0|     1018.0|         213.0|     663.0|     204.0|       1.6635|           67000.0|\n",
            "|  -121.43|   38.63|              43.0|     1009.0|         225.0|     604.0|     218.0|       1.6641|           67000.0|\n",
            "|  -120.65|   35.48|              19.0|     2310.0|         471.0|    1341.0|     441.0|        3.225|          166900.0|\n",
            "|  -122.84|    38.4|              15.0|     3080.0|         617.0|    1446.0|     599.0|       3.6696|          194400.0|\n",
            "|  -118.02|   34.08|              31.0|     2402.0|         632.0|    2830.0|     603.0|       2.3333|          164200.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prints structure of dataframe along with datatype\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "X1qnrZO3Pbs_",
        "outputId": "76abb833-5571-44d0-a721-db75d2db5dd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In our predictive model, below are the columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "a3koRaKBPdqG",
        "outputId": "466afec1-6c65-45b7-edc8-0b5a5812d03b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['longitude',\n",
              " 'latitude',\n",
              " 'housing_median_age',\n",
              " 'total_rooms',\n",
              " 'total_bedrooms',\n",
              " 'population',\n",
              " 'households',\n",
              " 'median_income',\n",
              " 'median_house_value']"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#columns identified as features are as below:\n",
        "#['Cruise_line','Age','Tonnage','passengers','length','cabins','passenger_density']\n",
        "#to work on the features, spark MLlib expects every value to be in numeric form\n",
        "#feature 'Cruise_line is string datatype\n",
        "#using StringIndexer, string type will be typecast to numeric datatype\n",
        "#import library strinindexer for typecasting\n",
        "  \n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer=StringIndexer(inputCol='latitude',outputCol='cruise_cat')\n",
        "indexed=indexer.fit(df).transform(df)\n",
        "  \n",
        "#above code will convert string to numeric feature and create a new dataframe\n",
        "#new dataframe contains a new feature 'cruise_cat' and can be used further\n",
        "#feature cruise_cat is now vectorized and can be used to fed to model\n",
        "for item in indexed.head(5):\n",
        "    print(item)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "l3JcMdbcPgo2",
        "outputId": "19df71c4-51a2-4cfc-df6f-c212e29941c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(longitude=-122.05, latitude=37.37, housing_median_age=27.0, total_rooms=3885.0, total_bedrooms=661.0, population=1537.0, households=606.0, median_income=6.6085, median_house_value=344700.0, cruise_cat=80.0)\n",
            "\n",
            "\n",
            "Row(longitude=-118.3, latitude=34.26, housing_median_age=43.0, total_rooms=1510.0, total_bedrooms=310.0, population=809.0, households=277.0, median_income=3.599, median_house_value=176500.0, cruise_cat=48.0)\n",
            "\n",
            "\n",
            "Row(longitude=-117.81, latitude=33.78, housing_median_age=27.0, total_rooms=3589.0, total_bedrooms=507.0, population=1484.0, households=495.0, median_income=5.7934, median_house_value=270500.0, cruise_cat=74.0)\n",
            "\n",
            "\n",
            "Row(longitude=-118.36, latitude=33.82, housing_median_age=28.0, total_rooms=67.0, total_bedrooms=15.0, population=49.0, households=11.0, median_income=6.1359, median_house_value=330000.0, cruise_cat=37.0)\n",
            "\n",
            "\n",
            "Row(longitude=-119.67, latitude=36.33, housing_median_age=19.0, total_rooms=1241.0, total_bedrooms=244.0, population=850.0, households=237.0, median_income=2.9375, median_house_value=81700.0, cruise_cat=168.0)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "#creating vectors from features\n",
        "#Apache MLlib takes input if vector form\n",
        "assembler=VectorAssembler(inputCols=['housing_median_age',\n",
        " 'total_rooms',\n",
        " 'total_bedrooms',\n",
        " 'population',\n",
        " 'households',\n",
        " 'median_income',\n",
        " 'cruise_cat'],outputCol='features')\n",
        "output=assembler.transform(indexed)\n",
        "output.select('features','median_house_value').show(5)\n",
        "#output as below"
      ],
      "metadata": {
        "id": "BARD-b8TPnv5",
        "outputId": "b415a82d-d6bb-4545-b10c-5b51cd332950",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|            features|median_house_value|\n",
            "+--------------------+------------------+\n",
            "|[27.0,3885.0,661....|          344700.0|\n",
            "|[43.0,1510.0,310....|          176500.0|\n",
            "|[27.0,3589.0,507....|          270500.0|\n",
            "|[28.0,67.0,15.0,4...|          330000.0|\n",
            "|[19.0,1241.0,244....|           81700.0|\n",
            "+--------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final data consist of features and label which is crew.\n",
        "final_data=output.select('features','median_house_value')\n",
        "#splitting data into train and test\n",
        "train_data,test_data=final_data.randomSplit([0.7,0.3])\n",
        "train_data.describe().show()"
      ],
      "metadata": {
        "id": "BdddEdKfQI7X",
        "outputId": "640f5fb5-da51-49db-9c79-560653a2cb68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|median_house_value|\n",
            "+-------+------------------+\n",
            "|  count|              2120|\n",
            "|   mean| 204656.0316037736|\n",
            "| stddev|113139.71957818244|\n",
            "|    min|           22500.0|\n",
            "|    max|          500001.0|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.describe().show()"
      ],
      "metadata": {
        "id": "8DjB9AJHQMz_",
        "outputId": "205648dc-d283-45a3-8b75-cae4f5df6c83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|median_house_value|\n",
            "+-------+------------------+\n",
            "|  count|               880|\n",
            "|   mean|208713.67954545454|\n",
            "| stddev|113084.24605369722|\n",
            "|    min|           47500.0|\n",
            "|    max|          500001.0|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import LinearRegression library\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "#creating an object of class LinearRegression\n",
        "#object takes features and label as input arguments\n",
        "ship_lr=LinearRegression(featuresCol='features',labelCol='crew')\n",
        "#pass train_data to train model\n",
        "trained_ship_model=ship_lr.fit(train_data)\n",
        "#evaluating model trained for Rsquared error\n",
        "ship_results=trained_ship_model.evaluate(train_data)\n",
        "  \n",
        "print('Rsquared Error :',ship_results.r2)\n",
        "#R2 value shows accuracy of model is 92%\n",
        "#model accuracy is very good and can be use for predictive analysis"
      ],
      "metadata": {
        "id": "KkXmLr-KQPVo",
        "outputId": "33e64aed-ae72-4086-af65-dc83fb7f8741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-9ca2aec96d43>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mship_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'crew'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#pass train_data to train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrained_ship_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mship_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#evaluating model trained for Rsquared error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mship_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_ship_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: crew does not exist. Available: features, median_house_value"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing Model on unlabeled data\n",
        "#create unlabeled data from test_data\n",
        "#testing model on unlabeled data\n",
        "unlabeled_data=test_data.select('features')\n",
        "unlabeled_data.show(5)"
      ],
      "metadata": {
        "id": "2KzbOz-bQTvf",
        "outputId": "7181bb1e-bd47-485f-a453-6ca6d01f7c30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|[1.0,83.0,15.0,32...|\n",
            "|[3.0,2821.0,519.0...|\n",
            "|[3.0,7689.0,1545....|\n",
            "|[4.0,1346.0,213.0...|\n",
            "|[4.0,1793.0,390.0...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=trained_ship_model.transform(unlabeled_data)\n",
        "predictions.show()\n",
        "#below are the results of output from test data"
      ],
      "metadata": {
        "id": "fqMOwGlmQTou",
        "outputId": "41a9a371-95c7-47c3-82b6-92dc2b6e3f41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|            features|        prediction|\n",
            "+--------------------+------------------+\n",
            "|[1.0,83.0,15.0,32...|  172807.032326014|\n",
            "|[3.0,2821.0,519.0...| 145449.3218103586|\n",
            "|[3.0,7689.0,1545....|168495.38897775538|\n",
            "|[4.0,1346.0,213.0...| 389991.2763938146|\n",
            "|[4.0,1793.0,390.0...|199831.68218252243|\n",
            "|[4.0,2372.0,361.0...| 209818.9794016584|\n",
            "|[4.0,2937.0,648.0...|202956.54363046767|\n",
            "|[4.0,6986.0,1217....|132385.05791640584|\n",
            "|[4.0,11021.0,1565...| 292284.4010842854|\n",
            "|[4.0,18123.0,3173...|319471.31908251636|\n",
            "|[4.0,21988.0,4055...|192206.37763677404|\n",
            "|[4.0,23915.0,4135...|211404.92761180399|\n",
            "|[5.0,906.0,187.0,...|148800.95741835865|\n",
            "|[5.0,1395.0,373.0...|133227.15089335683|\n",
            "|[5.0,1922.0,489.0...| 96093.28072383671|\n",
            "|[5.0,1998.0,500.0...|185808.68801913795|\n",
            "|[5.0,2256.0,420.0...|218073.08347404475|\n",
            "|[5.0,3846.0,786.0...|227835.42377252114|\n",
            "|[5.0,4303.0,613.0...|206311.30806858174|\n",
            "|[5.0,4413.0,804.0...| 205747.2465481292|\n",
            "+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}